{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbb9dfdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T23:08:04.171771Z",
     "iopub.status.busy": "2023-12-27T23:08:04.170844Z",
     "iopub.status.idle": "2023-12-27T23:08:17.388000Z",
     "shell.execute_reply": "2023-12-27T23:08:17.387025Z"
    },
    "papermill": {
     "duration": 13.317191,
     "end_time": "2023-12-27T23:08:17.390662",
     "exception": false,
     "start_time": "2023-12-27T23:08:04.073471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math as math\n",
    "\n",
    "data_dir = 'mnist-digits'\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eeb0afc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T23:08:17.586058Z",
     "iopub.status.busy": "2023-12-27T23:08:17.585157Z",
     "iopub.status.idle": "2023-12-27T23:08:32.465942Z",
     "shell.execute_reply": "2023-12-27T23:08:32.464625Z"
    },
    "papermill": {
     "duration": 14.978744,
     "end_time": "2023-12-27T23:08:32.468434",
     "exception": false,
     "start_time": "2023-12-27T23:08:17.489690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42000 files belonging to 10 classes.\n",
      "Using 33600 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-27 20:59:33.484637: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-27 20:59:33.486192: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42000 files belonging to 10 classes.\n",
      "Using 8400 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset='training',\n",
    "  shuffle=True,\n",
    "  seed=123,\n",
    "  image_size=(28, 28),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset='validation',\n",
    "  seed=123,\n",
    "  image_size=(28, 28),\n",
    "  batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88b67c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T23:08:32.660464Z",
     "iopub.status.busy": "2023-12-27T23:08:32.660039Z",
     "iopub.status.idle": "2023-12-27T23:08:32.665902Z",
     "shell.execute_reply": "2023-12-27T23:08:32.664909Z"
    },
    "papermill": {
     "duration": 0.103278,
     "end_time": "2023-12-27T23:08:32.668060",
     "exception": false,
     "start_time": "2023-12-27T23:08:32.564782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "train_num = 33600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc05b1b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T23:08:32.856249Z",
     "iopub.status.busy": "2023-12-27T23:08:32.855197Z",
     "iopub.status.idle": "2023-12-27T23:08:32.917957Z",
     "shell.execute_reply": "2023-12-27T23:08:32.916987Z"
    },
    "papermill": {
     "duration": 0.161133,
     "end_time": "2023-12-27T23:08:32.920611",
     "exception": false,
     "start_time": "2023-12-27T23:08:32.759478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize(images, labels):\n",
    "  images = tf.cast(images, float)\n",
    "  images /= 255\n",
    "  return images, labels\n",
    "\n",
    "#apply this function to every element in train and test data\n",
    "train_ds = train_ds.map(normalize)\n",
    "validation_ds = validation_ds.map(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48fb6de5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T23:08:33.108219Z",
     "iopub.status.busy": "2023-12-27T23:08:33.106994Z",
     "iopub.status.idle": "2023-12-27T23:08:33.158628Z",
     "shell.execute_reply": "2023-12-27T23:08:33.157602Z"
    },
    "papermill": {
     "duration": 0.148728,
     "end_time": "2023-12-27T23:08:33.161003",
     "exception": false,
     "start_time": "2023-12-27T23:08:33.012275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    #tf.keras.layers.RandomHeight(0.3),\n",
    "    #tf.keras.layers.RandomWidth(0.3),\n",
    "    tf.keras.layers.RandomZoom(0.3),\n",
    "    #tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu, input_shape=(28, 28, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2,2), strides=2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D((2,2), strides=2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), padding='same', activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D((2,2), strides=2),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acf1af68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T23:08:33.348030Z",
     "iopub.status.busy": "2023-12-27T23:08:33.347631Z",
     "iopub.status.idle": "2023-12-27T23:08:33.372037Z",
     "shell.execute_reply": "2023-12-27T23:08:33.370881Z"
    },
    "papermill": {
     "duration": 0.12111,
     "end_time": "2023-12-27T23:08:33.374555",
     "exception": false,
     "start_time": "2023-12-27T23:08:33.253445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832bf150",
   "metadata": {
    "papermill": {
     "duration": 0.090986,
     "end_time": "2023-12-27T23:08:33.557210",
     "exception": false,
     "start_time": "2023-12-27T23:08:33.466224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1423daee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T23:08:33.741272Z",
     "iopub.status.busy": "2023-12-27T23:08:33.740894Z",
     "iopub.status.idle": "2023-12-27T23:09:50.331309Z",
     "shell.execute_reply": "2023-12-27T23:09:50.330225Z"
    },
    "papermill": {
     "duration": 76.685103,
     "end_time": "2023-12-27T23:09:50.333720",
     "exception": false,
     "start_time": "2023-12-27T23:08:33.648617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "1050/1050 [==============================] - 130s 122ms/step - loss: 0.5481 - accuracy: 0.8163\n",
      "Epoch 2/2\n",
      "1050/1050 [==============================] - 112s 107ms/step - loss: 0.2204 - accuracy: 0.9308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd780c80880>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=2, steps_per_epoch=math.ceil(train_num/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0554c35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T23:09:50.722927Z",
     "iopub.status.busy": "2023-12-27T23:09:50.722188Z",
     "iopub.status.idle": "2023-12-27T23:09:56.566119Z",
     "shell.execute_reply": "2023-12-27T23:09:56.565281Z"
    },
    "papermill": {
     "duration": 6.071131,
     "end_time": "2023-12-27T23:09:56.568418",
     "exception": false,
     "start_time": "2023-12-27T23:09:50.497287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 2s 7ms/step - loss: 0.1075 - accuracy: 0.9665\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2610fe78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T23:09:56.907450Z",
     "iopub.status.busy": "2023-12-27T23:09:56.906716Z",
     "iopub.status.idle": "2023-12-27T23:09:58.662861Z",
     "shell.execute_reply": "2023-12-27T23:09:58.661870Z"
    },
    "papermill": {
     "duration": 1.927244,
     "end_time": "2023-12-27T23:09:58.665448",
     "exception": false,
     "start_time": "2023-12-27T23:09:56.738204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model_save')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 861823,
     "sourceId": 3004,
     "sourceType": "competition"
    },
    {
     "datasetId": 1272,
     "sourceId": 2280,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 155.415919,
   "end_time": "2023-12-27T23:10:01.329019",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-27T23:07:25.913100",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
